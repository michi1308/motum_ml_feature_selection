{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ec3df9-3a3f-4230-9286-b0cfc867ced0",
   "metadata": {},
   "source": [
    "Modelle vergleichen über CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f15d60-4a8a-4f6a-8dbe-bbf43ec87de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# Führt CV durch und berechnet die Metriken\n",
    "def repeated_k_fold(model, X, y, n_splits=5, n_repeats=10):\n",
    "    rkf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
    "\n",
    "    accuracy_train, accuracy_test = [], []\n",
    "    f1, recall, roc_auc = [], [], []\n",
    "\n",
    "    for train_index, test_index in rkf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy_train.append(accuracy_score(y_train, y_train_pred))\n",
    "        accuracy_test.append(accuracy_score(y_test, y_test_pred))\n",
    "        f1.append(f1_score(y_test, y_test_pred))\n",
    "        recall.append(recall_score(y_test, y_test_pred))\n",
    "        roc_auc.append(roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "    return {\n",
    "        \"Train Accuracy\": (np.mean(accuracy_train), np.std(accuracy_train)),\n",
    "        \"Test Accuracy\": (np.mean(accuracy_test), np.std(accuracy_test)),\n",
    "        \"F1-Score_1\": (np.mean(f1), np.std(f1)),\n",
    "        \"Recall_1\": (np.mean(recall), np.std(recall)),\n",
    "        \"ROC-AUC_1\": (np.mean(roc_auc), np.std(roc_auc)),\n",
    "    }\n",
    "\n",
    "\n",
    "# Pfad zur Datei\n",
    "file_path = r\"K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML.xlsx\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Zielvariable (y) und Features (X) extrahieren\n",
    "    y = df['Verletzungsstatus']\n",
    "    \n",
    "    # Dummy-Variable \"Geschlecht_weiblich\" separieren\n",
    "    if 'Geschlecht_weiblich' in df.columns:\n",
    "        geschlecht_weiblich = df[['Geschlecht_weiblich']]\n",
    "        X = df.drop(columns=['Verletzungsstatus', 'Geschlecht_weiblich'])\n",
    "    else:\n",
    "        X = df.drop(columns=['Verletzungsstatus'])\n",
    "        geschlecht_weiblich = None  \n",
    "\n",
    "    # Skalierung der Features (ohne \"Geschlecht_weiblich\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Falls vorhanden, die Dummy-Variable wieder anhängen\n",
    "    if geschlecht_weiblich is not None:\n",
    "        X_scaled = np.hstack((X_scaled, geschlecht_weiblich.values))\n",
    "\n",
    "    # Modelle definieren\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42),\n",
    "        \"LightGBM\": LGBMClassifier(verbose=-1, random_state=42),\n",
    "        \"SVC\": SVC(probability=True, random_state=42),\n",
    "        \"k-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "        \"MLP Classifier\": MLPClassifier(max_iter=1000, random_state=42),\n",
    "        \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "        \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "        \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis(),\n",
    "        \"Bagging Classifier\": BaggingClassifier(random_state=42),\n",
    "        \"Extra Trees\": ExtraTreesClassifier(random_state=42),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Modell wird validiert: {model_name}\")\n",
    "        metrics = repeated_k_fold(model, X_scaled, y)  \n",
    "        \n",
    "        # Formatierung der Ergebnisse mit ±\n",
    "        formatted_metrics = {\n",
    "            \"Model\": model_name,\n",
    "            \"Train Accuracy\": f\"{metrics['Train Accuracy'][0]:.4f} ± {metrics['Train Accuracy'][1]:.4f}\",\n",
    "            \"Test Accuracy\": f\"{metrics['Test Accuracy'][0]:.4f} ± {metrics['Test Accuracy'][1]:.4f}\",\n",
    "            \"F1-Score_1\": f\"{metrics['F1-Score_1'][0]:.4f} ± {metrics['F1-Score_1'][1]:.4f}\",\n",
    "            \"Recall_1\": f\"{metrics['Recall_1'][0]:.4f} ± {metrics['Recall_1'][1]:.4f}\",\n",
    "            \"ROC-AUC_1\": f\"{metrics['ROC-AUC_1'][0]:.4f} ± {metrics['ROC-AUC_1'][1]:.4f}\",\n",
    "        }\n",
    "\n",
    "        results.append(formatted_metrics)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(by=\"ROC-AUC_1\", ascending=False)\n",
    "\n",
    "    print(\"\\nErgebnisse der Modelle:\")\n",
    "    print(results_df)\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Die Datei wurde nicht gefunden. Bitte überprüfe den Pfad.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ein Fehler ist aufgetreten: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b711e-4555-4c59-9abf-aa28d064a243",
   "metadata": {},
   "source": [
    "Mutual Information wird mit Korrelationsmatrix kombiniert und über Optuna-Optimierung werden die Variablen ausgewählt, die ROC-AUC optimieren.\n",
    "CV: split=5, repeats=10; r=0,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acbde32-5c12-49bc-855d-7c6046d56d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "\n",
    "# Laden der Daten\n",
    "def load_data(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    X = df.drop(columns=[\"Verletzungsstatus\"])\n",
    "    y = df[\"Verletzungsstatus\"]\n",
    "    return X, y\n",
    "\n",
    "# Vorverarbeitung der Daten\n",
    "def preprocess_data(X):\n",
    "    dummy_var = X[\"Geschlecht_weiblich\"]\n",
    "    cols_to_scale = [col for col in X.columns if col != \"Geschlecht_weiblich\"]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[cols_to_scale] = scaler.fit_transform(X[cols_to_scale])\n",
    "    X_scaled[\"Geschlecht_weiblich\"] = dummy_var  \n",
    "    return X_scaled\n",
    "\n",
    "# Auswahl an nicht hochkorrelierten Features herstellen\n",
    "def calculate_feature_selection(X_train, y_train, correlation_threshold=0.8):\n",
    "    # Berechnungen für Feature Selektion\n",
    "    correlation_matrix = X_train.corr().abs()\n",
    "    mutual_info = mutual_info_classif(X_train, y_train)\n",
    "    \n",
    "    # ausgewählte Features\n",
    "    selected_features = list(X_train.columns)  # Beginne mit allen Features\n",
    "    \n",
    "    # Iteriere über alle Feature-Paare\n",
    "    for col in X_train.columns:\n",
    "        if col in selected_features:\n",
    "            # Suche nach anderen hochkorrelierten Features\n",
    "            correlated_features = correlation_matrix[col].loc[correlation_matrix[col] > correlation_threshold].index.tolist()\n",
    "            correlated_features.remove(col)  # Entferne das aktuelle Feature selbst\n",
    "            \n",
    "            if correlated_features:\n",
    "                # Wenn es hochkorrelierte Features gibt, wähle das mit der höchsten Mutual Information\n",
    "                for correlated_feature in correlated_features:\n",
    "                    if mutual_info[X_train.columns.get_loc(col)] < mutual_info[X_train.columns.get_loc(correlated_feature)]:\n",
    "                        # Entferne das Feature mit der geringeren Mutual Information\n",
    "                        if col in selected_features:\n",
    "                            selected_features.remove(col)\n",
    "                    else:\n",
    "                        # Entferne das Feature mit der geringeren Mutual Information\n",
    "                        if correlated_feature in selected_features:\n",
    "                            selected_features.remove(correlated_feature)\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "\n",
    "# Optuna-Optimierung für äußere CV mit durchschnittlicher Anzahl an Features aus der inneren CV als Zielwert\n",
    "def optimize_feature_selection(X_train, y_train, target_num_features):\n",
    "    # Zuerst die nicht hochkorrelierten Features bestimmen\n",
    "    candidate_features = calculate_feature_selection(X_train, y_train, correlation_threshold=0.8)\n",
    "    candidate_features = sorted(candidate_features)\n",
    "    # Stelle sicher, dass target_num_features nicht größer als die Anzahl der Kandidaten ist:\n",
    "    target_num_features = min(target_num_features, len(candidate_features))\n",
    "    \n",
    "    def objective(trial):\n",
    "        # Der Suchraum orientiert sich an target_num_features, aber es darf nicht mehr als die\n",
    "        # vorhandenen Kandidatenfeatures ausgewählt werden.\n",
    "        num_features = trial.suggest_int(\n",
    "            \"num_features\",\n",
    "            max(5, target_num_features-5),\n",
    "            min(len(candidate_features), target_num_features+5)\n",
    "        )\n",
    "        \n",
    "        # Falls num_features größer als die Anzahl der Kandidatenfeatures sein könnte, beschränke sie\n",
    "        num_features = min(num_features, len(candidate_features))\n",
    "        \n",
    "        # Auswahl der ersten num_features aus dem Kandidatenpool\n",
    "        X_train_optimized = X_train[candidate_features[:num_features]]\n",
    "        \n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        score = cross_val_score(model, X_train_optimized, y_train, cv=5, scoring=\"roc_auc\", n_jobs=-1).mean()\n",
    "        return score\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "    return study.best_trial\n",
    "\n",
    "\n",
    "# komplette innere CV mit Berechnung der duchschnittlichen Anzahl an Features als Ausgabe\n",
    "def inner_cv_feature_selection(X_train, y_train):\n",
    "    inner_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    best_num_features = []\n",
    "    feature_counts = []  # Speichert die Anzahl der nicht hochkorrelierten Features pro Fold\n",
    "\n",
    "    for inner_train_idx, inner_test_idx in inner_cv.split(X_train, y_train):\n",
    "        X_inner_train, X_inner_test = X_train.iloc[inner_train_idx], X_train.iloc[inner_test_idx]\n",
    "        y_inner_train, y_inner_test = y_train.iloc[inner_train_idx], y_train.iloc[inner_test_idx]\n",
    "\n",
    "        # Berechne den Kandidatenpool\n",
    "        candidate_features = calculate_feature_selection(X_inner_train, y_inner_train, correlation_threshold=0.8)\n",
    "        candidate_features = sorted(candidate_features)\n",
    "        \n",
    "        # Speicher die Anzahl der übrig gebliebenen Features\n",
    "        feature_counts.append(len(candidate_features))\n",
    "        \n",
    "        # Falls der Kandidatenpool leer ist, setze alle Features ein\n",
    "        if len(candidate_features) == 0:\n",
    "            candidate_features = list(X_inner_train.columns)\n",
    "        \n",
    "        def objective(trial):\n",
    "            low_bound = 1\n",
    "            high_bound = len(candidate_features)\n",
    "            num_features = trial.suggest_int(\"num_features\", low_bound, high_bound)\n",
    "            X_selected = X_inner_train[candidate_features[:num_features]]\n",
    "\n",
    "            model = LogisticRegression(max_iter=1000)\n",
    "            score = cross_val_score(model, X_selected, y_inner_train, cv=5, scoring=\"roc_auc\", n_jobs=-1).mean()\n",
    "            return score\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=100, n_jobs=-1)\n",
    "        best_num_features.append(study.best_trial.params[\"num_features\"])\n",
    "        \n",
    "    # Berechnung von Median der besten Feature-Anzahl\n",
    "    median_features = int(np.median(best_num_features))\n",
    "\n",
    "    return median_features, feature_counts\n",
    "\n",
    "\n",
    "\n",
    "def cross_validate(X, y):\n",
    "    outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    \n",
    "    # Listen zum Sammeln der Metriken\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    f1_scores = []\n",
    "    recall_scores = []\n",
    "    roc_auc_scores = []\n",
    "    num_features = []\n",
    "    selected_features_outer = []\n",
    "    \n",
    "    all_feature_counts = []  # Hier speichern wir die Anzahl der nicht hochkorrelierten Features aus allen inneren CV-Folds\n",
    "\n",
    "    for outer_train_idx, outer_test_idx in outer_cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[outer_train_idx], X.iloc[outer_test_idx]\n",
    "        y_train, y_test = y.iloc[outer_train_idx], y.iloc[outer_test_idx]\n",
    "\n",
    "        # Innere Cross-Validation zur Berechnung der durchschnittlichen Anzahl an Features\n",
    "        avg_selected_features, feature_counts_inner = inner_cv_feature_selection(X_train, y_train)\n",
    "        \n",
    "        # Speichert alle Feature-Anzahlen der inneren CV-Folds über alle äußeren CV-Folds hinweg\n",
    "        all_feature_counts.extend(feature_counts_inner)  # Hier fügen wir die Werte aus innerer CV hinzu\n",
    "        \n",
    "        # Optuna-Optimierung in der äußeren CV, basierend auf der durchschnittlichen Anzahl der Features\n",
    "        candidate_features = calculate_feature_selection(X_train, y_train, correlation_threshold=0.8)\n",
    "        candidate_features = sorted(candidate_features)\n",
    "        trial = optimize_feature_selection(X_train[candidate_features], y_train, avg_selected_features)\n",
    "        num_features_optimized = trial.params['num_features']\n",
    "        \n",
    "        # Speichere die final ausgewählten Features für diesen Fold\n",
    "        selected_features_outer.append(candidate_features[:num_features_optimized])\n",
    "        \n",
    "        X_train_optimized = X_train[candidate_features[:num_features_optimized]]\n",
    "        X_test_optimized = X_test[candidate_features[:num_features_optimized]]\n",
    "\n",
    "        # Logistische Regression auf den selektierten Features\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train_optimized, y_train)\n",
    "        \n",
    "        # Vorhersagen\n",
    "        y_train_pred = model.predict(X_train_optimized)\n",
    "        y_test_pred = model.predict(X_test_optimized)\n",
    "\n",
    "        # Berechnungen der Metriken\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        f1 = f1_score(y_test, y_test_pred)\n",
    "        recall = recall_score(y_test, y_test_pred)\n",
    "        roc_auc = roc_auc_score(y_test, model.predict_proba(X_test_optimized)[:, 1])\n",
    "\n",
    "        # Speichern der Metriken\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        f1_scores.append(f1)\n",
    "        recall_scores.append(recall)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        num_features.append(num_features_optimized)\n",
    "    \n",
    "    results_summary = {\n",
    "        'Train Accuracy': np.mean(train_accuracies),\n",
    "        'Train Accuracy Std': np.std(train_accuracies),\n",
    "        'Test Accuracy': np.mean(test_accuracies),\n",
    "        'Test Accuracy Std': np.std(test_accuracies),\n",
    "        'F1-Score_1': np.mean(f1_scores),\n",
    "        'F1-Score Std': np.std(f1_scores),\n",
    "        'Recall_1': np.mean(recall_scores),\n",
    "        'Recall Std': np.std(recall_scores),\n",
    "        'ROC-AUC_1': np.mean(roc_auc_scores),\n",
    "        'ROC-AUC Std': np.std(roc_auc_scores),\n",
    "        'Feature-Anzahl': np.mean(num_features),\n",
    "        'Feature-Anzahl Std': np.std(num_features)\n",
    "    }\n",
    "\n",
    "    raw_metrics = {\n",
    "        \"Train Accuracies\": train_accuracies,\n",
    "        \"Test Accuracies\": test_accuracies,\n",
    "        \"F1 Scores\": f1_scores,\n",
    "        \"Recall Scores\": recall_scores,\n",
    "        \"ROC-AUC Scores\": roc_auc_scores,\n",
    "        \"Feature-Anzahlen\": num_features\n",
    "    }\n",
    "\n",
    "    return results_summary, raw_metrics, selected_features_outer, all_feature_counts\n",
    "\n",
    "\n",
    "def compute_feature_usage(selected_features_outer):\n",
    "    # Flache Liste aller ausgewählten Features aus den einzelnen Folds erstellen\n",
    "    all_selected_features = [feature for fold in selected_features_outer for feature in fold]\n",
    "    # Häufigkeiten zählen\n",
    "    feature_usage = Counter(all_selected_features)\n",
    "    # Filter nur Features, die mindestens einmal vorkamen (was per Definition immer der Fall ist)\n",
    "    most_common_features = feature_usage.most_common()\n",
    "    return most_common_features\n",
    "\n",
    "def compute_feature_stats(all_feature_counts):\n",
    "    # Berechnung der durchschnittlichen Anzahl der nicht hochkorrelierten Features\n",
    "    mean_features = np.mean(all_feature_counts)\n",
    "    std_features = np.std(all_feature_counts)\n",
    "    \n",
    "    # Rückgabe der berechneten Werte\n",
    "    return mean_features, std_features\n",
    "\n",
    "\n",
    "def display_results_summary(results_summary):\n",
    "    # Formatierte Metriken mit ± Standardabweichung\n",
    "    formatted_metrics = {\n",
    "        \"Gruppe\": [\"Total\", \"1 (Verletzte)\"],\n",
    "        \"Train Accuracy\": [\n",
    "            f\"{results_summary['Train Accuracy']*100:.2f} ± {results_summary['Train Accuracy Std']*100:.2f}\",\n",
    "            \"-\"\n",
    "        ],\n",
    "        \"Test Accuracy\": [\n",
    "            f\"{results_summary['Test Accuracy']*100:.2f} ± {results_summary['Test Accuracy Std']*100:.2f}\",\n",
    "            \"-\"\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            \"-\",\n",
    "            f\"{results_summary['F1-Score_1']*100:.2f} ± {results_summary['F1-Score Std']*100:.2f}\"\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            \"-\",\n",
    "            f\"{results_summary['Recall_1']*100:.2f} ± {results_summary['Recall Std']*100:.2f}\"\n",
    "        ],\n",
    "        \"ROC-AUC\": [\n",
    "            f\"{results_summary['ROC-AUC_1']*100:.2f} ± {results_summary['ROC-AUC Std']*100:.2f}\",\n",
    "            f\"{results_summary['ROC-AUC_1']*100:.2f} ± {results_summary['ROC-AUC Std']*100:.2f}\"\n",
    "            \n",
    "        ],\n",
    "        \"Anzahl-Features\": [\n",
    "            f\"{results_summary['Feature-Anzahl']:.2f} ± {results_summary['Feature-Anzahl Std']:.2f}\",\n",
    "            \"-\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Erstellen des DataFrames\n",
    "    df = pd.DataFrame(formatted_metrics)\n",
    "\n",
    "    # Formatierung des DataFrames für HTML-Ausgabe\n",
    "    styled_df = df.style.set_properties(**{\"text-align\": \"center\", \"color\": \"black\"}) \\\n",
    "                        .set_table_styles([{\n",
    "                            \"selector\": \"th\", \n",
    "                            \"props\": [(\"font-size\", \"14px\"), \n",
    "                                      (\"background-color\", \"#f2f2f2\"), \n",
    "                                      (\"color\", \"black\")]\n",
    "                        }]) \\\n",
    "                        .set_caption(\"Durchschnittliche Evaluierungsmetriken über die äußere CV\")\n",
    "\n",
    "    display(styled_df)\n",
    "\n",
    "\n",
    "def plot_raw_metrics(raw_metrics):\n",
    "    # Erstellen eines DataFrames für die fünf Metriken\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Train Accuracy\": raw_metrics[\"Train Accuracies\"],\n",
    "        \"Test Accuracy\": raw_metrics[\"Test Accuracies\"],\n",
    "        \"F1 Score\": raw_metrics[\"F1 Scores\"],\n",
    "        \"Recall\": raw_metrics[\"Recall Scores\"],\n",
    "        \"ROC-AUC\": raw_metrics[\"ROC-AUC Scores\"]\n",
    "    })\n",
    "    \n",
    "    # Umwandlung in das Long-Format (tidy data)\n",
    "    metrics_long = metrics_df.melt(var_name=\"Metrik\", value_name=\"Wert\")\n",
    "    \n",
    "    # Erstellen des Boxplots für die fünf Metriken\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(x=\"Wert\", y=\"Metrik\", data=metrics_long)\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.title(\"Verteilung der Evaluierungsmetriken über die äußere CV\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Erstellen eines separaten DataFrames für die Feature-Anzahl\n",
    "    features_df = pd.DataFrame({\n",
    "        \"Feature-Anzahl\": raw_metrics[\"Feature-Anzahlen\"]\n",
    "    })\n",
    "    \n",
    "    # Erstellen eines separaten Boxplots für die Feature-Anzahl\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=\"Feature-Anzahl\", data=features_df)\n",
    "    plt.xlabel(\"Feature-Anzahl\")\n",
    "    plt.title(\"Verteilung der Feature-Anzahlen über die äußere CV\")\n",
    "    plt.show()\n",
    "\n",
    "def print_feature_importance_table(most_common_features):\n",
    "    # Erstelle ein DataFrame aus dem Counter\n",
    "    df_features = pd.DataFrame(most_common_features, columns=[\"Feature\", \"Häufigkeit\"])\n",
    "    # Formatierung der Tabelle\n",
    "    styled_df = df_features.style.set_properties(**{\"text-align\": \"center\", \"color\": \"black\"}) \\\n",
    "                         .set_table_styles([{\"selector\": \"th\", \n",
    "                                              \"props\": [(\"font-size\", \"14px\"), \n",
    "                                                        (\"background-color\", \"#f2f2f2\"), \n",
    "                                                        (\"color\", \"black\")]}]) \\\n",
    "                         .set_caption(\"Häufigste in der finalen Feature-Auswahl verwendete Features\")\n",
    "    display(styled_df)\n",
    "    \n",
    "def main():\n",
    "    file_path = r\"K:\\Team\\Böhmer_Michael\\TSA\\ML\\Basistabelle\\Basistabelle_ML.xlsx\"\n",
    "    X, y = load_data(file_path)\n",
    "    X_scaled = preprocess_data(X)\n",
    "    \n",
    "    results_summary, raw_metrics, selected_features_outer, all_feature_counts = cross_validate(X_scaled, y)\n",
    "    \n",
    "    print(\"\\nErgebnisse der äußeren Cross-Validation (aggregiert):\")\n",
    "    display_results_summary(results_summary)\n",
    "    \n",
    "    print(\"\\nVerteilung der Evaluierungsmetriken (Boxplot):\")\n",
    "    plot_raw_metrics(raw_metrics)\n",
    "    \n",
    "    # Berechne und zeige die Feature-Nutzung\n",
    "    most_common_features = compute_feature_usage(selected_features_outer)\n",
    "    print(\"\\nHäufigste verwendete Features:\")\n",
    "    print_feature_importance_table(most_common_features)\n",
    "    \n",
    "    # Berechne die durchschnittliche Anzahl nicht hochkorrelierter Features und gib das Ergebnis aus\n",
    "    mean_features, std_features = compute_feature_stats(all_feature_counts)\n",
    "    print(f\"\\nDurchschnittliche Anzahl nicht hochkorrelierter Features über alle inneren CVs: {mean_features:.2f} ± {std_features:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97d63ce-e072-4fb4-9a94-1c0900020d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'motum_ml_feature_selection'...\n",
      "warning: You appear to have cloned an empty repository.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/michi1308/motum_ml_feature_selection.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c048727-ecbb-4946-a02a-ba17b518f546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
